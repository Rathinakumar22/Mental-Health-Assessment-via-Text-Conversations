{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fdb9a11-fdb8-4371-86c8-15781bd19359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                               text  \\\n",
      "0           0  Welcome to /r/depression's check-in post - a p...   \n",
      "1           1  We understand that most people who reply immed...   \n",
      "2           2  Anyone else just miss physical touch? I crave ...   \n",
      "3           3  I’m just so ashamed. Everyone and everything f...   \n",
      "4           4  I really need a friend. I don't even have a si...   \n",
      "\n",
      "                                               title  target  \n",
      "0  Regular check-in post, with information about ...       1  \n",
      "1  Our most-broken and least-understood rules is ...       1  \n",
      "2  I haven’t been touched, or even hugged, in so ...       1  \n",
      "3                    Being Depressed is Embarrassing       1  \n",
      "4  I'm desperate for a friend and to feel loved b...       1  \n",
      "target\n",
      "1    1202\n",
      "3    1201\n",
      "4    1188\n",
      "2    1185\n",
      "0    1181\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('mentalhealth.csv')\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Check target distribution\n",
    "print(df['target'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a841e14-6ec6-441c-9442-bda76763e75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                               text  \\\n",
      "0           0  Welcome to /r/depression's check-in post - a p...   \n",
      "1           1  We understand that most people who reply immed...   \n",
      "2           2  Anyone else just miss physical touch? I crave ...   \n",
      "3           3  I’m just so ashamed. Everyone and everything f...   \n",
      "4           4  I really need a friend. I don't even have a si...   \n",
      "\n",
      "                                               title  target  \\\n",
      "0  Regular check-in post, with information about ...       1   \n",
      "1  Our most-broken and least-understood rules is ...       1   \n",
      "2  I haven’t been touched, or even hugged, in so ...       1   \n",
      "3                    Being Depressed is Embarrassing       1   \n",
      "4  I'm desperate for a friend and to feel loved b...       1   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  welcome /r/depression's check-in post - place ...  \n",
      "1  understand people reply immediately op invitat...  \n",
      "2      anyone else miss physical touch? crave badly…  \n",
      "3  i’m ashamed. everyone everything feels far awa...  \n",
      "4  really need friend. even single best friend i'...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('mentalhealth.csv')\n",
    "\n",
    "# Fill missing values in the text column with empty strings\n",
    "df['text'] = df['text'].fillna('')\n",
    "\n",
    "# Preprocessing: remove stopwords, lowercase the text\n",
    "def preprocess(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = str(text).lower()  # Ensure text is a string before processing\n",
    "    words = [word for word in text.split() if word not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply preprocessing to the text column\n",
    "df['cleaned_text'] = df['text'].apply(preprocess)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Display first few rows to check the preprocessing\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69ef7c8f-de7a-4e1d-bce3-02eb759ae1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.71      0.76       236\n",
      "           1       0.70      0.70      0.70       265\n",
      "           2       0.82      0.68      0.74       211\n",
      "           3       0.56      0.78      0.65       229\n",
      "           4       0.80      0.73      0.76       251\n",
      "\n",
      "    accuracy                           0.72      1192\n",
      "   macro avg       0.74      0.72      0.72      1192\n",
      "weighted avg       0.74      0.72      0.72      1192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Convert text into numerical features using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Train a Logistic Regression classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Display classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b1244d4-00e7-49f5-b3a1-ee13e098ed9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.06%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('mentalhealth.csv')\n",
    "\n",
    "# Fill missing values in the text column with empty strings\n",
    "df['text'] = df['text'].fillna('')\n",
    "\n",
    "# Preprocessing: remove stopwords, lowercase the text\n",
    "def preprocess(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = str(text).lower()  # Ensure text is a string before processing\n",
    "    words = [word for word in text.split() if word not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply preprocessing to the text column\n",
    "df['cleaned_text'] = df['text'].apply(preprocess)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text data into TF-IDF features\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Train a Logistic Regression classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save the trained models for future use\n",
    "with open('tfidf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "with open('classifier_model.pkl', 'wb') as f:\n",
    "    pickle.dump(classifier, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ea61df2-68d3-4427-b40e-ccc5dee5783f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Mental Health Condition: Stress\n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess new text input (similar to training data preprocessing)\n",
    "def preprocess_input(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = str(text).lower()  # Convert text to lowercase\n",
    "    words = [word for word in text.split() if word not in stop_words]  # Remove stopwords\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Sample new text input (replace this with your own test sentences)\n",
    "new_text = \"I have been feeling very stressed and anxious lately.\"\n",
    "\n",
    "# Preprocess the new text\n",
    "cleaned_new_text = preprocess_input(new_text)\n",
    "\n",
    "# Transform the new text using the saved TF-IDF vectorizer\n",
    "new_text_tfidf = tfidf.transform([cleaned_new_text])\n",
    "\n",
    "# Predict the mental health condition using the saved classifier\n",
    "predicted_label = classifier.predict(new_text_tfidf)\n",
    "\n",
    "# Mapping the predicted label to the mental health condition\n",
    "label_mapping = {0: \"Stress\", 1: \"Depression\", 2: \"Bipolar disorder\", 3: \"Personality disorder\", 4: \"Anxiety\"}\n",
    "predicted_condition = label_mapping[predicted_label[0]]\n",
    "\n",
    "print(f\"Predicted Mental Health Condition: {predicted_condition}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5baccb66-d3f4-45db-a3f5-64a4ef492756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I feel extremely hopeless and sad.\n",
      "Predicted Mental Health Condition: Depression\n",
      "\n",
      "Input: I'm struggling with mood swings and extreme irritability.\n",
      "Predicted Mental Health Condition: Bipolar disorder\n",
      "\n",
      "Input: I have been really anxious about everything recently.\n",
      "Predicted Mental Health Condition: Anxiety\n",
      "\n",
      "Input: I'm finding it hard to control my emotions.\n",
      "Predicted Mental Health Condition: Bipolar disorder\n",
      "\n",
      "Input: I've been feeling a lot better lately, much happier.\n",
      "Predicted Mental Health Condition: Personality disorder\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additional test cases\n",
    "test_texts = [\n",
    "    \"I feel extremely hopeless and sad.\",\n",
    "    \"I'm struggling with mood swings and extreme irritability.\",\n",
    "    \"I have been really anxious about everything recently.\",\n",
    "    \"I'm finding it hard to control my emotions.\",\n",
    "    \"I've been feeling a lot better lately, much happier.\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    cleaned_text = preprocess_input(text)\n",
    "    transformed_text = tfidf.transform([cleaned_text])\n",
    "    predicted_label = classifier.predict(transformed_text)\n",
    "    predicted_condition = label_mapping[predicted_label[0]]\n",
    "    print(f\"Input: {text}\\nPredicted Mental Health Condition: {predicted_condition}\\n\")\n",
    "/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "230f5dad-ce37-4bed-a598-75be055ba695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "              Stress       0.82      0.71      0.76       236\n",
      "          Depression       0.70      0.70      0.70       265\n",
      "    Bipolar disorder       0.82      0.68      0.74       211\n",
      "Personality disorder       0.56      0.78      0.65       229\n",
      "             Anxiety       0.80      0.73      0.76       251\n",
      "\n",
      "            accuracy                           0.72      1192\n",
      "           macro avg       0.74      0.72      0.72      1192\n",
      "        weighted avg       0.74      0.72      0.72      1192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = classifier.predict(tfidf.transform(X_test))\n",
    "\n",
    "# Print detailed classification report\n",
    "print(classification_report(y_test, y_pred, target_names=label_mapping.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b58403-7fc9-42f8-beff-c8cf0d3400c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
